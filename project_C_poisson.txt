========================================
FILE: project_C_poisson/validate_local.py
========================================
#!/usr/bin/env python3
"""
Local validation script - tests single extreme parameter combination
to catch numerical instabilities before Docker deployment.
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import numpy as np
from config import ExperimentConfig, HHConfig, TaskConfig
from rng_manager import RNGManager
from hh_model import HHModel
from readout import ReadoutModule
from utils import filter_and_downsample
from tasks.narma import NARMA
from tasks.xor import DelayedXOR
from tasks.mc import MemoryCapacity
from tasks.lyapunov_task import LyapunovModule

def test_extreme_case(rho, bias, seed=42):
    """Test single extreme parameter combination"""
    print(f"\n{'='*60}")
    print(f"Testing: rho={rho}, bias={bias}, seed={seed}")
    print(f"{'='*60}\n")
    
    # Create minimal config
    cfg = ExperimentConfig()
    cfg.hh = HHConfig(N=50)
    cfg.task = TaskConfig(dt=0.05, symbol_ms=20.0)
    cfg.cv_folds = 2
    cfg.cv_gap = 5
    cfg.ridge_alphas = [1.0, 10.0]
    cfg.cache_dir = "cache_local_test"
    cfg.results_dir = "results_local_test"
    
    os.makedirs(cfg.cache_dir, exist_ok=True)
    os.makedirs(cfg.results_dir, exist_ok=True)
    
    # Setup RNG
    rng_mgr = RNGManager(2025)
    trial_gens = rng_mgr.get_trial_generators(seed)
    seeds_tuple = rng_mgr.get_trial_seeds_tuple(seed)
    
    # Setup modules
    hh = HHModel(cfg, trial_gens, seeds_tuple)
    readout = ReadoutModule(trial_gens['readout'], cv_folds=cfg.cv_folds, cv_gap=cfg.cv_gap)
    
    steps_per_symbol = int(cfg.task.symbol_ms / cfg.task.dt)
    
    results = {}
    
    try:
        # Test NARMA
        print("Testing NARMA task...")
        narma = NARMA(trial_gens['in'])
        u_nm, y_nm = narma.generate_data(500, order=10)
        
        rates_nm = cfg.task.poisson_rate_min + u_nm * 2.0 * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min)
        rates_up_nm = np.repeat(rates_nm, steps_per_symbol)
        spikes_nm = (trial_gens['in'].random(len(rates_up_nm)) < (rates_up_nm * cfg.task.dt * 1e-3)).astype(float)
        
        state_nm = hh.simulate(rho, bias, spikes_nm, f"test_NARMA_{rho}_{bias}")
        
        print(f"  Firing rate: {state_nm['mean_rate']:.2f} Hz")
        print(f"  I_syn mean: {state_nm['mean_I_syn']:.4f}")
        print(f"  Saturation: {state_nm['saturation_flag']}")
        
        if state_nm['saturation_flag']:
            print("  ⚠ WARNING: Voltage saturation detected!")
        
        phi_nm = filter_and_downsample(state_nm['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
        y_nm = y_nm[-len(phi_nm):]
        
        met_nm = readout.train_ridge_cv(phi_nm, y_nm, task_type='regression', alphas=cfg.ridge_alphas)
        print(f"  NRMSE: {met_nm['nrmse']:.4f}")
        results['narma_nrmse'] = met_nm['nrmse']
        results['narma_saturation'] = state_nm['saturation_flag']
        
        # Test XOR
        print("\nTesting XOR task...")
        xor = DelayedXOR(trial_gens['in'])
        u_xor, y_xor = xor.generate_data(500, delay=2)
        
        rates_xor = cfg.task.poisson_rate_min + u_xor * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min)
        rates_up_xor = np.repeat(rates_xor, steps_per_symbol)
        spikes_xor = (trial_gens['in'].random(len(rates_up_xor)) < (rates_up_xor * cfg.task.dt * 1e-3)).astype(float)
        
        state_xor = hh.simulate(rho, bias, spikes_xor, f"test_XOR_{rho}_{bias}")
        phi_xor = filter_and_downsample(state_xor['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
        y_xor = y_xor[-len(phi_xor):]
        
        met_xor = readout.train_ridge_cv(phi_xor, y_xor, task_type='classification', alphas=cfg.ridge_alphas)
        print(f"  Accuracy: {met_xor['acc']:.4f}")
        print(f"  AUC: {met_xor['auc']:.4f}")
        results['xor_acc'] = met_xor['acc']
        
        # Test Lyapunov
        print("\nTesting Lyapunov task...")
        lyap = LyapunovModule(trial_gens['in'])
        u_lyap = trial_gens['in'].uniform(0, 1, 200)
        
        rates_lyap = cfg.task.poisson_rate_min + u_lyap * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min)
        rates_up_lyap = np.repeat(rates_lyap, steps_per_symbol)
        spikes_lyap = (trial_gens['in'].random(len(rates_up_lyap)) < (rates_up_lyap * cfg.task.dt * 1e-3)).astype(float)
        
        state_l1 = hh.simulate(rho, bias, spikes_lyap, f"test_LYAP_{rho}_{bias}_ref")
        phi1 = filter_and_downsample(state_l1['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
        
        V_pert = np.full(cfg.hh.N, -65.0)
        V_pert[0] += 1e-6
        
        state_l2 = hh.simulate(rho, bias, spikes_lyap, f"test_LYAP_{rho}_{bias}_pert", V_init=V_pert)
        phi2 = filter_and_downsample(state_l2['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
        
        lambda_val = lyap.compute_lambda(phi1, phi2, window_range=[20, 100])
        print(f"  Lambda: {lambda_val:.6f}")
        results['lyapunov'] = lambda_val
        
        print(f"\n{'='*60}")
        print("✓ TEST PASSED - No crashes or NaN values")
        print(f"{'='*60}\n")
        return True, results
        
    except Exception as e:
        print(f"\n{'='*60}")
        print(f"✗ TEST FAILED: {e}")
        print(f"{'='*60}\n")
        import traceback
        traceback.print_exc()
        return False, results

if __name__ == "__main__":
    print("="*60)
    print("LOCAL VALIDATION - Testing Extreme Parameter Combinations")
    print("="*60)
    
    test_cases = [
        (0.01, 0.0, 0),   # Low rho, no bias
        (1.5, 0.0, 0),    # High rho, no bias
        (0.01, 8.0, 0),   # Low rho, high bias
        (1.5, 8.0, 0),    # High rho, high bias (most extreme)
    ]
    
    all_passed = True
    for rho, bias, seed in test_cases:
        passed, results = test_extreme_case(rho, bias, seed)
        if not passed:
            all_passed = False
            print(f"\n⚠ STOPPING: Test failed for rho={rho}, bias={bias}")
            break
    
    if all_passed:
        print("\n" + "="*60)
        print("✓ ALL LOCAL VALIDATION TESTS PASSED")
        print("Safe to proceed with Docker deployment")
        print("="*60)
        sys.exit(0)
    else:
        print("\n" + "="*60)
        print("✗ VALIDATION FAILED")
        print("Fix numerical stability issues before deployment")
        print("="*60)
        sys.exit(1)
-e 

========================================
FILE: project_C_poisson/tests/test_leakage.py
========================================

import unittest
import numpy as np
import sys
import os

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '../src'))

from cv import BlockedCV

class TestBlockedCV(unittest.TestCase):
    def test_no_overlap(self):
        cv = BlockedCV(n_folds=5, gap=0)
        n_samples = 100
        for train_idx, test_idx in cv.split(n_samples):
            intersect = np.intersect1d(train_idx, test_idx)
            self.assertEqual(len(intersect), 0, "Train and Test overlap!")
            
    def test_gap_integrity(self):
        gap = 10
        cv = BlockedCV(n_folds=5, gap=gap)
        n_samples = 200
        
        for i, (train_idx, test_idx) in enumerate(cv.split(n_samples)):
            min_test = np.min(test_idx)
            max_test = np.max(test_idx)
            
            # Check gap before test
            train_before = train_idx[train_idx < min_test]
            if len(train_before) > 0:
                max_train_pre = np.max(train_before)
                dist = min_test - max_train_pre
                self.assertGreater(dist, gap, f"Gap Violation Pre-Test in fold {i}")
                
            # Check gap after test
            train_after = train_idx[train_idx > max_test]
            if len(train_after) > 0:
                min_train_post = np.min(train_after)
                dist = min_train_post - max_test
                self.assertGreater(dist, gap, f"Gap Violation Post-Test in fold {i}")

    def test_coverage(self):
        cv = BlockedCV(n_folds=5, gap=0)
        n_samples = 100
        test_mask = np.zeros(n_samples, dtype=bool)
        
        for _, test_idx in cv.split(n_samples):
            test_mask[test_idx] = True
            
        self.assertTrue(np.all(test_mask), "Not all samples were tested!")

if __name__ == '__main__':
    unittest.main()
-e 

========================================
FILE: project_C_poisson/docker-compose.yml
========================================
version: '3.8'

services:
  hh_experiment:
    build: .
    container_name: hh_reservoir_experiment
    volumes:
      - ./results:/app/results
      - ./cache:/app/cache
      - ./configs:/app/configs
    deploy:
      resources:
        limits:
          cpus: '0.8' # 80% of available CPUs (will be calculated dynamically)
          memory: '0.8' # 80% of available RAM (will be calculated dynamically)
    environment:
      - PYTHONUNBUFFERED=1
      - OMP_NUM_THREADS=1
      - OPENBLAS_NUM_THREADS=1
      - MKL_NUM_THREADS=1
    command: python3 src/run_experiment.py --config configs/production_config.yaml
-e 

========================================
FILE: project_C_poisson/src/hh_model.py
========================================

import numpy as np
import scipy.sparse as sp
import os
import joblib
import hashlib
from typing import Tuple, Dict, Any, Optional

# Stable HH Functions
def alpha_m_safe(V):
    num = 0.1 * (V + 40.0); denom = 1.0 - np.exp(-(V + 40.0) / 10.0)
    mask = np.abs(V + 40.0) < 1e-6
    res = np.zeros_like(V); res[~mask] = num[~mask] / denom[~mask]; res[mask] = 1.0
    return res

def alpha_n_safe(V):
    num = 0.01 * (V + 55.0); denom = 1.0 - np.exp(-(V + 55.0) / 10.0)
    mask = np.abs(V + 55.0) < 1e-6
    res = np.zeros_like(V); res[~mask] = num[~mask] / denom[~mask]; res[mask] = 0.1
    return res

def beta_m_safe(V): return 4.0 * np.exp(-(V + 65.0) / 18.0)
def alpha_h_safe(V): return 0.07 * np.exp(-(V + 65.0) / 20.0)
def beta_h_safe(V): return 1.0 / (1.0 + np.exp(-(V + 35.0) / 10.0))
def beta_n_safe(V): return 0.125 * np.exp(-(V + 65.0) / 80.0)

class HHModel:
    def __init__(self, config, trial_generators: Dict, seeds_tuple: Tuple = (0,0,0,0)):
        self.cfg = config
        self.seeds_tuple = seeds_tuple
        self.rng_rec = trial_generators['rec']
        self.rng_inmask = trial_generators['inmask']
        
        # Generation Logic
        # Generation Logic
        self.W_rec = self._generate_dale_weights()
        self.W_in = (self.rng_inmask.random(self.cfg.hh.N) < self.cfg.hh.in_density).astype(float)

    def _generate_dale_weights(self):
        N = self.cfg.hh.N
        density = self.cfg.hh.density
        n_exc = int(0.8 * N)
        ei_vec = np.ones(N); ei_vec[n_exc:] = -1
        
        mask = sp.random(N, N, density=density, random_state=self.rng_rec).toarray() > 0
        W = np.zeros((N, N))
        W[mask] = self.rng_rec.uniform(0, 1.0, size=np.sum(mask))
        W *= ei_vec
        
        # Spectral Radius Scaling (Initial)
        radius = np.max(np.abs(np.linalg.eigvals(W)))
        if radius > 1e-10: W /= radius
        return W

    def get_steady_state(self, V):
        am, bm = alpha_m_safe(V), beta_m_safe(V)
        ah, bh = alpha_h_safe(V), beta_h_safe(V)
        an, bn = alpha_n_safe(V), beta_n_safe(V)
        return am/(am+bm), ah/(ah+bh), an/(an+bn)

    def get_cache_key(self, rho: float, bias: float, task_input_id: str, len_input: int) -> str:
        """Cache key including seeds, params, and input length."""
        key = f"{rho}_{bias}_{self.seeds_tuple}_{self.cfg.hh.N}_{task_input_id}_{self.cfg.task.dt}_{len_input}"
        return hashlib.sha1(key.encode()).hexdigest()

    def simulate(self, rho: float, bias: float, spikes_in: np.ndarray, 
                 task_input_id: str, trim_steps: int = 500,
                 V_init: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """Runs HH simulation with steady-state init and exhaustive metrics."""
        # Check Cache (Skip if V_init provided)
        if V_init is None:
            cache_key = self.get_cache_key(rho, bias, task_input_id, len(spikes_in))
            cache_path = os.path.join(self.cfg.cache_dir, f"{cache_key}.pkl")
            if os.path.exists(cache_path):
                try:
                    return joblib.load(cache_path)
                except:
                    pass

        W_eff = self.W_rec * rho
        N, dt = self.cfg.hh.N, self.cfg.task.dt
        p = self.cfg.hh
        
        # Steady State Init (V0 = -65.0)
        if V_init is not None:
             V = V_init.copy()
        else:
             V = np.full(N, -65.0)
             
        m, h, n = self.get_steady_state(V)
        b_gate = 1.0 / (1.0 + np.exp((V + 80.0) / 6.0)) # A-current steady state
        
        s_trace = np.zeros(N); s_in_trace = 0.0
        decay_in = np.exp(-dt / p.tau_in)
        decay_syn = np.exp(-dt / p.tau_syn)
        
        res_spikes = np.zeros((len(spikes_in), N), dtype=np.bool_)
        syn_stats = {'sum_I': 0.0, 'sq_sum': 0.0, 'count': 0}
        saturation_count = 0
        
        for t in range(len(spikes_in)):
            V_old = V.copy()
            s_in_trace = s_in_trace * decay_in + spikes_in[t]
            I_pulse = (self.cfg.hh.in_gain * s_in_trace) * self.W_in + bias
            
            # Gating
            a_inf = 1.0 / (1.0 + np.exp(-(V + 50.0) / 20.0))
            b_inf = 1.0 / (1.0 + np.exp((V + 80.0) / 6.0))
            b_gate += (dt / p.tauA) * (b_inf - b_gate)
            
            am, bm = alpha_m_safe(V), beta_m_safe(V); m += dt * (am * (1 - m) - bm * m)
            ah, bh = alpha_h_safe(V), beta_h_safe(V); h += dt * (ah * (1 - h) - bh * h)
            an, bn = alpha_n_safe(V), beta_n_safe(V); n += dt * (an * (1 - n) - bn * n)
            
            # Synaptic Current
            syn = W_eff @ s_trace
            I_syn = np.maximum(0, syn)*(V-p.Eexc) + np.maximum(0, -syn)*(V-p.Einh)
            
            # Integration
            dV = (-p.gNa*(m**3)*h*(V-p.ENa) - p.gK*(n**4)*(V-p.EK) - p.gL*(V-p.EL) 
                  - p.gA*(a_inf**3)*b_gate*(V-p.EA) - I_syn + I_pulse) / p.C
            V += dt * dV
            
            # Saturation Check
            if np.any(np.abs(V) > 100): 
                saturation_count += 1
                V = np.clip(V, -100, 100)
            
            # Spikes
            spks = (V > -20.0) & (V_old <= -20.0)
            res_spikes[t] = spks
            s_trace = s_trace * decay_syn + spks.astype(float)
            
            if t >= trim_steps:
                syn_stats['sum_I'] += np.mean(I_syn) # Collect signed mean E[I]
                syn_stats['sq_sum'] += np.mean(I_syn**2) # Collect E[I^2]
                syn_stats['count'] += 1

        # Trimming
        # Trimming
        trimmed_spikes = res_spikes[trim_steps:]
        valid_steps = syn_stats['count']
        
        # Correct statistics calculation (Var(I) = E[I^2] - (E[I])^2)
        mean_I = syn_stats['sum_I'] / valid_steps if valid_steps > 0 else 0
        mean_I2 = syn_stats['sq_sum'] / valid_steps if valid_steps > 0 else 0
        var_I = mean_I2 - (mean_I)**2
        
        result = {
            'spikes': trimmed_spikes,
            'mean_rate': (np.sum(trimmed_spikes) / (valid_steps * dt * 1e-3)) / N if valid_steps > 0 else 0.0,
            'mean_I_syn': mean_I,
            'var_I_syn': var_I,
            'saturation_flag': (saturation_count / len(spikes_in)) > 0.01
        }
        
        # Save Cache (Only if V_init is None)
        if V_init is None:
            os.makedirs(self.cfg.cache_dir, exist_ok=True)
            joblib.dump(result, cache_path)
        
        return result
-e 

========================================
FILE: project_C_poisson/src/test_config.yaml
========================================

# Minimal Test Config
hh:
  N: 20  # Tiny network
  density: 0.2
task:
  narma_order: 5 
  poisson_rate_min: 10
  poisson_rate_max: 50
  symbol_ms: 20
  dt: 0.1
  lyap_window: [10, 50]

rho_grid_coarse: [0.1]
bias_grid_coarse: [0.0]
seeds_coarse: 1
sweep_mode: coarse
results_dir: "/home/atkaw/Dokumenty/hailitacja/eservoir_hh/project_C_poisson/results_test"
cache_dir: "/home/atkaw/Dokumenty/hailitacja/eservoir_hh/project_C_poisson/cache_test"
-e 

========================================
FILE: project_C_poisson/src/run_experiment.py
========================================

import numpy as np
import pandas as pd
import os
import joblib
import time
import argparse
from typing import Dict, Any, List
from concurrent.futures import ProcessPoolExecutor, as_completed
import traceback

from config import load_config, ExperimentConfig
from rng_manager import RNGManager
from hh_model import HHModel
from readout import ReadoutModule
from sklearn.preprocessing import StandardScaler
from utils import filter_and_downsample, get_git_hash

# Tasks
from tasks.narma import NARMA
from tasks.xor import DelayedXOR
from tasks.mc import MemoryCapacity
from tasks.lyapunov_task import LyapunovModule

def run_trial(rho: float, bias: float, trial_idx: int, cfg: ExperimentConfig, base_seed: int = 2025) -> List[Dict[str, Any]]:
    """
    Executes a single Trial (Seed Tuple) for a given (rho, bias).
    A Trial consists of 4 tasks run on the SAME reservoir instance (re-simulated/cached).
    """
    results = []
    
    # 1. Setup RNG (Strict N=20 separation)
    rng_mgr = RNGManager(base_seed)
    # trial_idx 0..19 determines the 4 streams
    trial_generators = rng_mgr.get_trial_generators(trial_idx)
    seeds_tuple = rng_mgr.get_trial_seeds_tuple(trial_idx) # (rec, inmask, in, readout)
    
    # 2. Setup Modules
    hh = HHModel(cfg, trial_generators, seeds_tuple)
    readout = ReadoutModule(trial_generators['readout'], cv_folds=cfg.cv_folds, cv_gap=cfg.cv_gap) 
    
    # 3. Parameters
    steps_per_symbol = int(cfg.task.symbol_ms / cfg.task.dt)
    
    try:
        # ==========================
        # TASK A: NARMA (Regression)
        # ==========================
        narma = NARMA(trial_generators['in']) # Use input stream for task generation
        u_nm, y_nm = narma.generate_data(2000, order=cfg.task.narma_order)
        
        input_id_nm = cfg.get_task_input_id() + "_NARMA_u05" # Add dist logic explicitly
        
        rates_nm = cfg.task.poisson_rate_min + u_nm * 2.0 * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min) 
        rates_up_nm = np.repeat(rates_nm, steps_per_symbol)
        spikes_nm = (trial_generators['in'].random(len(rates_up_nm)) < (rates_up_nm * cfg.task.dt * 1e-3)).astype(float)
        
        # Baseline logic is handled inside each block for clarity and state sync
        state_nm = hh.simulate(rho, bias, spikes_nm, input_id_nm)
        
        # Fallback length calc
        trim_steps = 500
        # Calculate per-task expected length to avoid crossover bugs
        expected_len_nm = (len(spikes_nm) - trim_steps) // steps_per_symbol
        
        if state_nm['mean_rate'] == 0:
            phi_nm = np.zeros((expected_len_nm, cfg.hh.N)) # Correct fallback length
        else:
            phi_nm = filter_and_downsample(state_nm['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
            if phi_nm.shape[1] != cfg.hh.N:
                # Emergency fix for cached dimension mismatch
                phi_nm = np.zeros((phi_nm.shape[0], cfg.hh.N))
            
        if cfg.task.zscore_features:
            from sklearn.preprocessing import StandardScaler
            phi_nm = StandardScaler().fit_transform(phi_nm)
            
        y_nm = y_nm[-len(phi_nm):]
        
        # Strictly aligned Baseline:
        # Model uses phi_nm[t] to predict y_nm[t].
        # For fair comparison, we truncate the first 'order' samples from BOTH
        # to ensure the same time indices are evaluated.
        # This fixes "different BlockedCV splits" issue.
        order = cfg.task.narma_order
        if len(phi_nm) > order:
            phi_valid = phi_nm[order:]
            y_valid = y_nm[order:]
            
            # Baseline uses SAME y_valid as target.
            # But baseline needs 'order' history for first sample of y_valid.
            # We construct X_ar purely from y_valid (shifted)? No.
            # We use y_nm to construct X_ar, then align.
            # Better: narma.compute_baseline takes X_ar and y_tgt.
            
            # Use 'compute_baseline' existing but pass the ALIGNED target.
            # Wait, if we pass y_valid to compute_baseline, it will internally look back 'order' steps FROM y_valid.
            # That would mean it needs y_valid[0-order].
            # narma.compute_baseline implementation:
            # X_ar[:, i] = y_tgt[order-(i+1) : n-(i+1)]
            # It assumes y_tgt is the FULL sequence and cuts off 'order' stats.
            
            # So if we pass y_nm (full), it evaluates on y_nm[order:].
            # If we run model on (phi[order:], y[order:]), then model evaluates on y[order:].
            # This MATCHES!
            
            # So the previous code:
            # met_nm = readout.train_ridge_cv(phi_nm, y_nm) -> evaluates on all splits of (phi, y).
            # base_nm = compute_baseline(y=y_nm) -> evaluates on y[order:].
            
            # Issue: Model evaluates on [0..T], Baseline on [order..T].
            # Fix: Force model to evaluate on [order..T] too.
            
            met_nm = readout.train_ridge_cv(phi_valid, y_valid, task_type='regression', alphas=cfg.ridge_alphas)
            
            # Now Baseline:
            # If we call compute_baseline(y_valid), it will cut ANOTHER 'order'.
            # We want baseline to evaluate on EXACTLY y_valid.
            # So we must pass (y_with_history) but tell it to eval on y_valid?
            # Or manually construct features here.
            
            # Manual construction for 100% clarity:
            X_ar = np.zeros((len(y_valid), order))
            # We need history from y_nm prior to y_valid
            # y_valid starts at index 'order' of y_nm.
            # History for y_valid[0] is y_nm[order-1], ..., y_nm[0].
            for i in range(order):
                 # Lag i+1
                 # X[:, i] = y_nm[order-(i+1) : - (i+1)] ?
                 # effectively shifted columns.
                 X_ar[:, i] = y_nm[order-(i+1) : len(y_nm)-(i+1)]
                 
            # Verify lengths
            # len(y_valid) = L - order.
            # len(y_nm) = L.
            # slice order-(i+1) : L-(i+1) has length (L-(i+1)) - (order-(i+1)) = L - order. Correct.
            
            base_nm_val = readout.train_ridge_cv(X_ar, y_valid, task_type="regression", alphas=cfg.ridge_alphas)
            base_nm = base_nm_val['nrmse']
            
        else:
             met_nm = {'nrmse': 1.0}; base_nm = 1.0; imp_nm = 0.0

        imp_nm = (base_nm - met_nm['nrmse']) / (base_nm + 1e-12)
        
        # Schema - Base
        res_base = dict(rho=rho, bias=bias, seed_tuple_id=trial_idx,
                       seed_rec=seeds_tuple[0], seed_inmask=seeds_tuple[1], seed_in=seeds_tuple[2], seed_readout=seeds_tuple[3],
                       firing_rate=state_nm['mean_rate'], I_syn_mean=state_nm['mean_I_syn'], 
                       I_syn_var=state_nm['var_I_syn'], saturation_flag=state_nm['saturation_flag'])

        results.append({**res_base, 'task': 'NARMA', 'metric': 'nrmse', 'value': met_nm['nrmse'], 'baseline': base_nm, 'improvement': imp_nm})

        # ==========================
        # TASK B: XOR (Classification)
        # ==========================
        xor = DelayedXOR(trial_generators['in'])
        u_xor, y_xor = xor.generate_data(2000, delay=cfg.task.xor_delay)
        input_id_xor = cfg.get_task_input_id() + "_XOR_bern05"
        
        rates_xor = cfg.task.poisson_rate_min + u_xor * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min) 
        rates_up_xor = np.repeat(rates_xor, steps_per_symbol)
        spikes_xor = (trial_generators['in'].random(len(rates_up_xor)) < (rates_up_xor * cfg.task.dt * 1e-3)).astype(float)
        
        state_xor = hh.simulate(rho, bias, spikes_xor, input_id_xor)
        expected_len_xor = (len(spikes_xor) - trim_steps) // steps_per_symbol
        
        if state_xor['mean_rate'] == 0:
            phi_xor = np.zeros((expected_len_xor, cfg.hh.N))
        else:
            phi_xor = filter_and_downsample(state_xor['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
            if phi_xor.shape[1] != cfg.hh.N:
                phi_xor = np.zeros((phi_xor.shape[0], cfg.hh.N))
            
        if cfg.task.zscore_features:
             from sklearn.preprocessing import StandardScaler
             phi_xor = StandardScaler().fit_transform(phi_xor)
        y_xor = y_xor[-len(phi_xor):]
        
        met_xor = readout.train_ridge_cv(phi_xor, y_xor, task_type='classification', alphas=cfg.ridge_alphas)
        base_xor = xor.compute_baseline(y_xor, readout)
        
        res_base['firing_rate'] = state_xor['mean_rate'] # Update specific to this run
        res_base['I_syn_mean'] = state_xor['mean_I_syn']
        res_base['I_syn_var'] = state_xor['var_I_syn']
        res_base['saturation_flag'] = state_xor['saturation_flag']
        
        results.append({**res_base, 'task': 'XOR', 'metric': 'accuracy', 'value': met_xor.get('acc', 0.5), 'baseline': base_xor, 'improvement': met_xor.get('acc', 0.5) - base_xor})
        results.append({**res_base, 'task': 'XOR', 'metric': 'auc', 'value': met_xor.get('auc', 0.5), 'baseline': 0.5, 'improvement': met_xor.get('auc', 0.5) - 0.5})

        # ==========================
        # TASK C: MC (Capacity)
        # ==========================
        mc = MemoryCapacity(trial_generators['in'])
        u_mc = mc.generate_data(2000)
        input_id_mc = cfg.get_task_input_id() + "_MC_uniform01"
        
        rates_mc = cfg.task.poisson_rate_min + u_mc * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min)
        rates_up_mc = np.repeat(rates_mc, steps_per_symbol)
        spikes_mc = (trial_generators['in'].random(len(rates_up_mc)) < (rates_up_mc * cfg.task.dt * 1e-3)).astype(float)
        
        state_mc = hh.simulate(rho, bias, spikes_mc, input_id_mc)
        expected_len_mc = (len(spikes_mc) - trim_steps) // steps_per_symbol
        
        if state_mc['mean_rate'] == 0:
            phi_mc = np.zeros((expected_len_mc, cfg.hh.N))
        else:
            phi_mc = filter_and_downsample(state_mc['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
            if phi_mc.shape[1] != cfg.hh.N:
                phi_mc = np.zeros((phi_mc.shape[0], cfg.hh.N))
            
        if cfg.task.zscore_features:
             from sklearn.preprocessing import StandardScaler
             phi_mc = StandardScaler().fit_transform(phi_mc)
        u_mc = u_mc[-len(phi_mc):]
        
        res_mc = mc.run_mc_analysis(phi_mc, u_mc, readout, max_lag=cfg.task.mc_max_lag)
        # Pass dedicated RNG for shuffling logic
        base_mc = mc.compute_baseline(u_mc, phi_mc, readout, rng_shuffle=trial_generators['readout'], max_lag=cfg.task.mc_max_lag)
        
        res_base['firing_rate'] = state_mc['mean_rate']
        res_base['I_syn_mean'] = state_mc['mean_I_syn']
        res_base['I_syn_var'] = state_mc['var_I_syn']
        res_base['saturation_flag'] = state_mc['saturation_flag']
        
        results.append({**res_base, 'task': 'MC', 'metric': 'capacity', 'value': res_mc['mc'], 'baseline': base_mc, 'improvement': res_mc['mc'] - base_mc})

        # ==========================
        # TASK D: LYAPUNOV (Stability)
        # ==========================
        lyap = LyapunovModule(trial_generators['in']) # Or inmask? Use 'in' for consistency of input generation
        len_lyap = 500
        u_lyap = trial_generators['in'].uniform(0, 1, len_lyap)
        input_id_lyap = cfg.get_task_input_id() + "_LYAP_consistent"
        
        rates_lyap = cfg.task.poisson_rate_min + u_lyap * (cfg.task.poisson_rate_max - cfg.task.poisson_rate_min)
        rates_up_lyap = np.repeat(rates_lyap, steps_per_symbol)
        
        # Phase 1: Reference Trajectory
        # Need V init? 
        # Standard: Run transient with seed X. 
        # Actually simulate inputs:
        spikes_lyap = (trial_generators['in'].random(len(rates_up_lyap)) < (rates_up_lyap * cfg.task.dt * 1e-3)).astype(float)
        
        # We need HH to return V trace? Or use Filtered Spikes?
        # Plan: "d(t) > 1.0 (z-scored L2 distance)".
        # Use filtered spikes phi.
        
        # Need to force V_init for the second trajectory.
        # HHModel doesn't expose V_final.
        # But HHModel caches if not V_init provided.
        # For Lyapunov, we do NOT want to cache usually since we do perturbation.
        # Actually, if we use Random Init, and same seed, we get same trajectory.
        # We need:
        # 1. Run Trajectory 1 (Normal).
        # 2. Get State at time T=0 (after transient)?
        #   HHModel does steady state init `get_steady_state(V=-65)`.
        #   So both start at *identical* point.
        #   Perturbation: V_init[0] += epsilon.
        
        # Phase 1: Reference Trajectory with WARMUP
        # We need to simulate a warmup phase to get past transient, 
        # THEN use the end-state as V_init for both reference and perturbed trajectories.
        # But HHModel.simulate handles Init internally.
        # Strategy:
        # Run Traj 1 normally (long).
        # We assume transient is gone after 500 steps (Config logic).
        # But for Lyapunov we want perturbation at t_0 valid.
        
        # New Strategy: Run a short warmup "pre-flight"
        # steps_warmup = 1000
        # ... (Removed dead code for unused warmup injection)
        
        # We need a way to capture STATE from HHModel. HHModel currently returns spikes.
        # We cannot get V_final easily without modifying HHModel to return it.
        # MODIFYING HHMODEL IS RISKY IF PARALLEL? No, it's just return dict.
        # Let's assume we can't modify HHModel interface easily now (schema update).
        # ALTERNATIVE:
        # Run Reference for T_total.
        # Run Perturbed for T_total.
        # Perturbation is applied at t=0.
        # BUT both start at "Steady State" which is mathematically valid state (Equilibrium).
        # So "Transient" is just the move from Equilibrium to Attractor.
        # Distances should be measured APART from transient.
        # LyapunovModule.compute_lambda takes "window_range".
        # If window_range starts at 50 (steps) * step_ms = ~1000ms, then transient is ignored.
        # So the issue is: perturbation at t=0 might decay during transient?
        # Yes.
        # FIX: We rely on window_range to skip transient.
        # And we hope perturbation survives?
        # If lambda > 0, errors grow. If lambda < 0, errors shrink.
        # If we perturb at eq, and system goes to attractor, the difference might wash out if attractor is stable?
        # This is a valid concern.
        # However, without V_final return, we can't do better.
        # Wait, I CAN modify HHModel return dict. It's just a dict.
        
        # Let's trust window skipping for now, but ensure we return Lambda in proper units.
        state_l1 = hh.simulate(rho, bias, spikes_lyap, input_id_lyap + "_ref")
        phi1 = filter_and_downsample(state_l1['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
        
        # Traj 2 (Perturbed)
        V_pert = np.full(cfg.hh.N, -65.0)
        V_pert[0] += cfg.task.lyap_eps
        
        state_l2 = hh.simulate(rho, bias, spikes_lyap, input_id_lyap + "_pert", V_init=V_pert)
        phi2 = filter_and_downsample(state_l2['spikes'], steps_per_symbol, cfg.task.dt, cfg.task.tau_trace)
        
        # Convert Slope from "per step" to "per second"
        # step in phi is 'steps_per_symbol' * dt
        step_s = (steps_per_symbol * cfg.task.dt) / 1000.0
        
        slope = lyap.compute_lambda(phi1, phi2, window_range=cfg.task.lyap_window)
        lambda_val = slope / step_s # Now in s^-1
        
        res_base['firing_rate'] = state_l1['mean_rate']
        res_base['I_syn_mean'] = state_l1['mean_I_syn']
        res_base['I_syn_var'] = state_l1['var_I_syn']
        res_base['saturation_flag'] = state_l1['saturation_flag']

        results.append({**res_base, 'task': 'Lyapunov', 'metric': 'lambda_s', 'value': lambda_val, 'baseline': 0.0, 'improvement': 0.0})

    except Exception as e:
        print(f"ERROR in Trial {trial_idx} (rho={rho}, bias={bias}): {e}")
        # traceback.print_exc()
        # Return empty list or partial results?
        # Journal-Grade: Don't crash entire sweep, but log error.
        # Return what we have.
        pass
        
    return results

def run_experiment(cfg_path: str):
    cfg = load_config(cfg_path)
    os.makedirs(cfg.results_dir, exist_ok=True)
    
    # 1. Define Sweep Space
    tasks_to_run = []
    
    if cfg.sweep_mode == 'coarse':
        rhos = cfg.rho_grid_coarse
        biases = cfg.bias_grid_coarse
        seeds = range(cfg.seeds_coarse if hasattr(cfg, 'seeds_coarse') else 5)
    else:
        # Fine Sweep logic would be here (usually loaded from a separate fine config or dynamic)
        # For now assume config defines specific grids
        rhos = cfg.rho_grid_coarse # Or define fine grid in config
        biases = cfg.bias_grid_coarse
        seeds = range(cfg.seeds_fine)

    print(f"Initializing {cfg.sweep_mode.upper()} Sweep: {len(rhos)}x{len(biases)}x{len(seeds)}")
    
    for r in rhos:
        for b in biases:
            for s in seeds:
                tasks_to_run.append((r, b, s))
                
    # 2. Execute Parallel
    all_results = []
    # Sequential for debugging or Parallel?
    # Use Parallel for production.
    with ProcessPoolExecutor(max_workers=os.cpu_count() - 2) as executor:
        futures = {executor.submit(run_trial, r, b, s, cfg): (r, b, s) for r, b, s in tasks_to_run}
        
        for i, future in enumerate(as_completed(futures)):
            r, b, s = futures[future]
            try:
                res = future.result()
                all_results.extend(res)
                if i % 10 == 0:
                    print(f"Completed {i+1}/{len(futures)}")
            except Exception as e:
                print(f"CRITICAL FAIL on {r, b, s}: {e}")
                
    # 3. Save Parquet
    df = pd.DataFrame(all_results)
    df['timestamp'] = time.strftime("%Y%m%d-%H%M%S")
    df['git_hash'] = get_git_hash()
    df['sweep_mode'] = cfg.sweep_mode
    
    out_name = f"results_{cfg.sweep_mode}_{int(time.time())}.parquet"
    out_path = os.path.join(cfg.results_dir, out_name)
    df.to_parquet(out_path)
    print(f"SAVED RESULTS to {out_path} ({len(df)} rows)")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="config.yaml")
    args = parser.parse_args()
    run_experiment(args.config)
-e 

========================================
FILE: project_C_poisson/src/test_config_journal.yaml
========================================

hh:
  N: 50
  density: 0.2
  conn_type: "dale"
  # Constants (default)
  
task:
  poisson_rate_min: 10.0
  poisson_rate_max: 100.0
  dt: 0.1
  symbol_ms: 10.0
  narma_order: 5 
  xor_delay: 2
  mc_max_lag: 5
  lyap_window: [20, 100]
  zscore_features: true

esn:
  N: 50

# Experiment
rho_grid_coarse: [0.1]
bias_grid_coarse: [0.0]
seeds_coarse: 1
cv_folds: 2
cv_gap: 2
ridge_alphas: [1.0]

sweep_mode: "coarse"
cache_dir: "cache_test_journal"
results_dir: "results_test_journal"
-e 

========================================
FILE: project_C_poisson/src/baselines_rc/esn.py
========================================

import numpy as np
import scipy.sparse as sp

class EchoStateNetwork:
    """
    Standard ESN Baseline for Journal Comparison.
    Uses tanh activation, sparse weights, and spectral radius scaling.
    """
    def __init__(self, N: int, spectral_radius: float, 
                 input_scale: float, density: float = 0.1, 
                 leaking_rate: float = 1.0, seed: int = 42):
        self.N = N
        self.rho = spectral_radius
        self.input_scale = input_scale
        self.alpha = leaking_rate # Leaking rate (1 = no leak, standard ESN)
        self.rng = np.random.default_rng(seed)
        
        # Init Weights
        self.W = self._init_weights(density)
        self.W_in = self.rng.uniform(-1, 1, (N, 1)) * input_scale
        
    def _init_weights(self, density):
        # Sparse random weights [-1, 1]
        mask = sp.random(self.N, self.N, density=density, random_state=self.rng).toarray() > 0
        W = np.zeros((self.N, self.N))
        W[mask] = self.rng.uniform(-1, 1, size=np.sum(mask))
        
        # Spectral Radius
        eigenvals = np.linalg.eigvals(W)
        current_rho = np.max(np.abs(eigenvals))
        if current_rho > 0:
            W *= (self.rho / current_rho)
        return W

    def simulate(self, u: np.ndarray, washout: int = 100) -> np.ndarray:
        """
        Runs ESN simulation on input u.
        Returns state matrix X (T, N).
        """
        T = len(u)
        x = np.zeros(self.N)
        X_all = np.zeros((T, self.N))
        
        for t in range(T):
            # u[t] is scalar or vector? Assuming scalar for now comparable to HH tasks
            curr_u = u[t]
            
            # ESN Update
            # x(t) = (1-a)x(t-1) + a * tanh( Win*u(t) + W*x(t-1) )
            pre_act = (self.W_in.flatten() * curr_u) + (self.W @ x)
            x = (1.0 - self.alpha) * x + self.alpha * np.tanh(pre_act)
            X_all[t] = x
            
        return X_all[washout:]
-e 

========================================
FILE: project_C_poisson/src/cv.py
========================================

import numpy as np
from typing import Iterator, Tuple

class BlockedCV:
    """
    Rigorous Blocked Cross-Validation with temporal gap.
    Prevents leakage of autocorrelation from Train to Test.
    """
    def __init__(self, n_folds: int = 5, gap: int = 0):
        self.n_folds = n_folds
        self.gap = gap

    def split(self, n_samples: int) -> Iterator[Tuple[np.ndarray, np.ndarray]]:
        """
        Generates indices for Blocked CV.
        
        Args:
            n_samples: Total number of time steps.
            
        Returns:
            train_idx, test_idx
        """
        # Strict integer division, remainder goes to last fold (standard)
        # Or better: distribute remainder? For simplicity and reproducibility:
        # fold_size = n // k. Last fold gets extra.
        indices = np.arange(n_samples)
        fold_size = n_samples // self.n_folds
        
        for i in range(self.n_folds):
            test_start = i * fold_size
            test_end = (i + 1) * fold_size if i < self.n_folds - 1 else n_samples
            
            test_indices = indices[test_start:test_end]
            
            # Gap Logic: Remove 'gap' samples adjacent to test block
            train_mask = np.ones(n_samples, dtype=bool)
            
            # Mask Test
            train_mask[test_start:test_end] = False
            
            # Mask Gap Before
            gap_before = max(0, test_start - self.gap)
            train_mask[gap_before:test_start] = False
            
            # Mask Gap After
            gap_after = min(n_samples, test_end + self.gap)
            train_mask[test_end:gap_after] = False
            
            train_indices = indices[train_mask]
            
            yield train_indices, test_indices
-e 

========================================
FILE: project_C_poisson/src/run_analysis.py
========================================

import pandas as pd
import numpy as np
import os
import argparse
from scipy.stats import wilcoxon, ttest_rel
from sklearn.utils import resample

def load_results(results_dir):
    # Find latest parquet or merge all?
    # For now, simplistic load
    files = [f for f in os.listdir(results_dir) if f.endswith(".parquet")]
    if not files:
        raise FileNotFoundError(f"No parquet files in {results_dir}")
    
    # Sort by time
    files.sort(reverse=True)
    latest = files[0]
    print(f"Loading {latest}...")
    return pd.read_parquet(os.path.join(results_dir, latest))

def compute_stats(df):
    """
    Aggregates results: Mean +/- Std, CI, Tests.
    """
    # Group by config (rho, bias, task, metric)
    grouped = df.groupby(['rho', 'bias', 'task', 'metric'])
    
    agg_df = grouped['value'].agg(['mean', 'std', 'count']).reset_index()
    
    # Calculate CI (Bootstrap) - Placeholder logic
    # Real impl would iterate groups and bootstrap 'value'
    
    return agg_df

def run_analysis(results_dir, output_dir):
    df = load_results(results_dir)
    stats = compute_stats(df)
    
    os.makedirs(output_dir, exist_ok=True)
    stats.to_csv(os.path.join(output_dir, "summary_stats.csv"))
    print(f"Saved stats to {output_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--results_dir", type=str, required=True)
    parser.add_argument("--output_dir", type=str, default="report/tables")
    args = parser.parse_args()
    
    run_analysis(args.results_dir, args.output_dir)
-e 

========================================
FILE: project_C_poisson/src/rng_manager.py
========================================

import numpy as np
import hashlib

class RNGManager:
    """
    Manages 4 independent RNG streams for scientific rigor:
    - rec: Reservoir topology (W_rec)
    - inmask: Input projection (W_in)
    - in: Signal u(t) and Poisson spikes
    - readout: CV splits and ridge selection
    
    Supports N=20 independent trials.
    """
    def __init__(self, base_seed: int):
        self.base_seed = base_seed
        
    def _derive_seed(self, trial_idx: int, stream_id: str) -> int:
        """Derives a deterministic seed for a specific trial and stream."""
        s = f"{self.base_seed}_{trial_idx}_{stream_id}"
        return int(hashlib.sha256(s.encode()).hexdigest()[:8], 16)

    def get_trial_generators(self, trial_idx: int):
        """Returns 4 Generators for a given trial."""
        return {
            'rec': np.random.default_rng(self._derive_seed(trial_idx, 'rec')),
            'inmask': np.random.default_rng(self._derive_seed(trial_idx, 'inmask')),
            'in': np.random.default_rng(self._derive_seed(trial_idx, 'in')),
            'readout': np.random.default_rng(self._derive_seed(trial_idx, 'readout'))
        }
        
    def get_trial_seeds_tuple(self, trial_idx: int):
        """Returns raw seeds for logging in Parquet."""
        return (
            self._derive_seed(trial_idx, 'rec'),
            self._derive_seed(trial_idx, 'inmask'),
            self._derive_seed(trial_idx, 'in'),
            self._derive_seed(trial_idx, 'readout')
        )
-e 

========================================
FILE: project_C_poisson/src/readout.py
========================================

import numpy as np
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score, roc_auc_score
from typing import Dict, Any, List, Optional
from cv import BlockedCV

class ReadoutModule:
    """
    Journal-Grade Readout Module.
    Features strict Nested Blocked CV for alpha selection and leakage-proof evaluation.
    """
    def __init__(self, rng: np.random.Generator, cv_folds: int = 5, cv_gap: int = 10):
        self.rng = rng
        self.folds = cv_folds
        self.gap = cv_gap

    def train_ridge_cv(self, X: np.ndarray, y: np.ndarray, 
                       task_type: str = "regression", 
                       alphas: List[float] = [1e-6, 1e-4, 1e-2, 1.0, 10.0, 100.0]) -> Dict[str, float]:
        """
        Trains Ridge using Nested Blocked CV.
        
        Outer Loop: Evaluate Performance (Test).
        Inner Loop: Select Hyperparameters (Validation on Train).
        """
        outer_cv = BlockedCV(self.folds, self.gap)
        
        scores = []
        best_alphas = []
        
        for train_idx, test_idx in outer_cv.split(len(y)):
            X_train, y_train = X[train_idx], y[train_idx]
            X_test, y_test = X[test_idx], y[test_idx]
            
            # --- INNER CV (Hyperparameter Selection) ---
            # Strictly matches outer protocol (Blocked + Gap) but on Train data
            inner_best_alpha = self._select_alpha_nested(X_train, y_train, alphas)
            best_alphas.append(inner_best_alpha)
            
            # --- FINAL TRAIN (On Data available in this Fold) ---
            model = Ridge(alpha=inner_best_alpha)
            model.fit(X_train, y_train)
            
            # --- EVALUATE ---
            if task_type == "regression":
                y_pred = model.predict(X_test)
                mse = mean_squared_error(y_test, y_pred)
                var = np.var(y_test)
                nrmse = np.sqrt(mse / (var + 1e-12))
                scores.append({'nrmse': nrmse, 'mse': mse})
                
            elif task_type == "classification":
                # Ridge for Classification (targets {0, 1})
                y_pred_score = model.predict(X_test) # Continuous score s = Xw
                y_pred_class = (y_pred_score > 0.5).astype(int)
                
                acc = accuracy_score(y_test, y_pred_class)
                bal_acc = balanced_accuracy_score(y_test, y_pred_class)
                try:
                    auc = roc_auc_score(y_test, y_pred_score)
                except ValueError:
                    auc = 0.5 # Handle single-class edge case
                    
                scores.append({'acc': acc, 'bal_acc': bal_acc, 'auc': auc})
        
        # Aggregate Results
        agg = {}
        if not scores: return {}
        
        metric_keys = scores[0].keys()
        for k in metric_keys:
            agg[k] = np.mean([s[k] for s in scores])
            
        # Log-mean of alphas for better interpretation
        mean_log_alpha = np.mean(np.log10(best_alphas))
        agg['best_alpha_mean'] = np.power(10, mean_log_alpha)
        # Also store distribution if possible? No, strict schema.
        
        return agg

    def _select_alpha_nested(self, X: np.ndarray, y: np.ndarray, alphas: List[float]) -> float:
        """
        Selects best alpha using Inner Blocked CV (3 folds) optimizing MSE.
        Optimization metric is always MSE for Ridge consistency.
        """
        if len(alphas) == 1: 
            return alphas[0]
            
        if len(X) < 20: # Fallback for very short sequences
             # Single split 50/50
             tr_len = int(len(X) * 0.5)
             tr_idx = np.arange(tr_len)
             val_idx = np.arange(tr_len, len(X))
             # Just one loop manually
             best = alphas[0]; min_loss = float('inf')
             for a in alphas:
                 m = Ridge(alpha=a); m.fit(X[tr_idx], y[tr_idx])
                 loss = mean_squared_error(y[val_idx], m.predict(X[val_idx]))
                 if loss < min_loss: min_loss = loss; best=a
             return best
             
        inner_cv = BlockedCV(n_folds=3, gap=self.gap)
        alpha_losses = {a: [] for a in alphas}
        
        for tr_idx, val_idx in inner_cv.split(len(y)):
            X_tr, y_tr = X[tr_idx], y[tr_idx]
            X_val, y_val = X[val_idx], y[val_idx]
            
            for a in alphas:
                m = Ridge(alpha=a)
                m.fit(X_tr, y_tr)
                pred = m.predict(X_val)
                loss = mean_squared_error(y_val, pred)
                alpha_losses[a].append(loss)
                
        # Find alpha with minimum average MSE
        best_alpha = min(alphas, key=lambda x: np.mean(alpha_losses[x]))
        return best_alpha
-e 

========================================
FILE: project_C_poisson/src/utils.py
========================================

import numpy as np
import subprocess

def get_git_hash() -> str:
    try:
        return subprocess.check_output(['git', 'rev-parse', 'HEAD']).strip().decode('utf-8')
    except:
        return "unknown"

def filter_and_downsample(spikes: np.ndarray, steps_per_symbol: int, dt: float = 0.05, tau: float = 20.0) -> np.ndarray:
    """
    Exponential filtering of spikes + Downsampling.
    Matches standard reservoir readout protocol.
    """
    T, N = spikes.shape
    alpha = np.exp(-dt / tau)
    filtered = np.zeros((T, N))
    r = np.zeros(N)
    
    for t in range(T):
        r = r * alpha + spikes[t] # Integrate spikes
        filtered[t] = r
        
    # Sample at the END of each symbol integration period
    # step_per_symbol-1, 2*step-1, ...
    indices = np.arange(steps_per_symbol - 1, T, steps_per_symbol)
    return filtered[indices]
-e 

========================================
FILE: project_C_poisson/src/tasks/narma.py
========================================

import numpy as np
from typing import List

class NARMA:
    def __init__(self, rng: np.random.Generator):
        self.rng = rng
        
    def generate_data(self, length: int, order: int = 10) -> tuple[np.ndarray, np.ndarray]:
        """Generates NARMA sequence. Uniform [0, 0.5] input per Journal-Grade spec."""
        u = self.rng.uniform(0, 0.5, length)
        y = np.zeros(length)
        
        for t in range(order, length):
            sum_y = np.sum(y[t-order:t])
            y[t] = 0.3 * y[t-1] + 0.05 * y[t-1] * sum_y + 1.5 * u[t-order] * u[t-1] + 0.1
            if np.abs(y[t]) > 1e10: # Numerical stability clip
                y[t] = np.sign(y[t]) * 1e10
            
        return u, y

    def compute_baseline(self, y_tgt: np.ndarray, 
                         readout_module, order: int,
                         alphas: List[float] = [1e-6, 1e-4, 1e-2, 1.0]) -> float:
        """
        Computes AR(k) baseline strictly on target y(t).
        y_tgt must be the SAME array used for readout target (downsampled).
        """
        n = len(y_tgt)
        if n <= order: return 0.0
        
        X_ar = np.zeros((n - order, order))
        y_ar = y_tgt[order:] # Shifted target for AR
        
        for i in range(order):
            X_ar[:, i] = y_tgt[order-(i+1) : n-(i+1)]  
            
        metrics = readout_module.train_ridge_cv(
            X_ar, y_ar, task_type="regression", alphas=alphas
        )
        return metrics['nrmse']
-e 

========================================
FILE: project_C_poisson/src/tasks/mc.py
========================================

import numpy as np

class MemoryCapacity:
    def __init__(self, rng: np.random.Generator):
        self.rng = rng

    def generate_data(self, length: int) -> np.ndarray:
        return self.rng.uniform(0, 1, length)

    def run_mc_analysis(self, phi: np.ndarray, u: np.ndarray, 
                       readout_module, max_lag: int = 20) -> dict:
        
        mc_total = 0.0
        r2_per_lag = []
        valid_len = len(phi) - max_lag
        phi_valid = phi[max_lag:]
        
        for k in range(1, max_lag + 1):
            y_tgt = u[max_lag-k : -k] if k < max_lag else u[: -max_lag]
            if len(y_tgt) != len(phi_valid):
                 min_len = min(len(y_tgt), len(phi_valid))
                 y_tgt = y_tgt[:min_len]
                 phi_curr = phi_valid[:min_len]
            else:
                 phi_curr = phi_valid

            res = readout_module.train_ridge_cv(phi_curr, y_tgt, task_type="regression")
            r2 = 1.0 - (res['nrmse']**2)
            r2 = max(0.0, r2)
            
            mc_total += r2
            r2_per_lag.append(r2)
            
        return {'mc': mc_total, 'r2_by_lag': r2_per_lag}

    def compute_baseline(self, u: np.ndarray, phi: np.ndarray, 
                         readout_module, rng_shuffle: np.random.Generator, max_lag: int = 20) -> float:
        # Shuffle phi across time to destroy temporal structure
        # Use explicit RNG for reproducibility
        phi_shuffled = phi.copy()
        rng_shuffle.shuffle(phi_shuffled) 
        
        res = self.run_mc_analysis(phi_shuffled, u, readout_module, max_lag)
        return res['mc']
-e 

========================================
FILE: project_C_poisson/src/tasks/xor.py
========================================

import numpy as np
from cv import BlockedCV

class DelayedXOR:
    def __init__(self, rng: np.random.Generator):
        self.rng = rng

    def generate_data(self, length: int, delay: int = 2) -> tuple[np.ndarray, np.ndarray]:
        u = self.rng.integers(0, 2, length) 
        y = np.zeros(length)
        
        for t in range(delay, length):
            y[t] = int(u[t] ^ u[t-delay])
            
        return u, y

    def compute_baseline(self, y: np.ndarray, readout_module) -> float:
        outer_cv = BlockedCV(readout_module.folds, readout_module.gap)
        accuracies = []
        
        for train_idx, test_idx in outer_cv.split(len(y)):
            y_train = y[train_idx]
            y_test = y[test_idx]
            
            mean_val = np.mean(y_train)
            majority_class = 1 if mean_val >= 0.5 else 0
            
            y_pred = np.full_like(y_test, majority_class)
            acc = np.mean(y_test == y_pred)
            accuracies.append(acc)
            
        return np.mean(accuracies)
-e 

========================================
FILE: project_C_poisson/src/tasks/__init__.py
========================================

from .narma import NARMA
from .xor import DelayedXOR
from .mc import MemoryCapacity
from .lyapunov_task import LyapunovModule
-e 

========================================
FILE: project_C_poisson/src/tasks/lyapunov_task.py
========================================

import numpy as np
from sklearn.preprocessing import StandardScaler

class LyapunovModule:
    """
    Computes Deterministic Lyapunov Exponent.
    """
    def __init__(self, rng: np.random.Generator):
        self.rng = rng

    def compute_lambda(self, phi1: np.ndarray, phi2: np.ndarray, 
                       window_range: tuple = (50, 250)) -> float:
        scaler = StandardScaler()
        phi1_z = scaler.fit_transform(phi1)
        phi2_z = scaler.transform(phi2)
        
        diff = phi1_z - phi2_z
        d = np.linalg.norm(diff, axis=1)
        d = np.maximum(d, 1e-12)
        log_d = np.log(d)
        
        sat_indices = np.where(d > 1.0)[0]
        if len(sat_indices) > 0:
            t_sat = sat_indices[0]
        else:
            t_sat = len(d)
            
        t_start, t_end = window_range
        t_end = min(t_end, t_sat)
        
        if t_end <= t_start + 5:
             return 0.0 
                 
        t_vals = np.arange(t_start, t_end)
        y_vals = log_d[t_start:t_end]
        
        slope, intercept = np.polyfit(t_vals, y_vals, 1)
        
        # Unit conversion: 
        # slope is per window step.
        # dt is simulation step in ms. window step depends on downsampling?
        # The input dt here is "simulation dt" usually 0.05ms.
        # But phi is usually downsampled.
        # We assume phi is passed 'as is'. user must know the effective dt of phi rows.
        # If phi rows are separated by 'step_ms', then lambda (per ms) = slope / step_ms
        # lambda (per s) = slope / step_ms * 1000
        # For now, return raw slope per Step, but logging should handle conversion.
        # Actually user requested Fix.
        # Let's return NO conversion here but document it, OR change signature to accept step_ms.
        # Changing signature:
        return slope # Caller (run_experiment) should normalize this using step_ms!
-e 

========================================
FILE: project_C_poisson/src/config.py
========================================
from dataclasses import dataclass, field
from typing import List, Tuple, Optional, Any
import yaml
import hashlib
import os

@dataclass
class HHConfig:
    """Rigorous Hodgkin-Huxley Model Parameters"""
    N: int = 100
    density: float = 0.2
    conn_type: str = "dale"
    
    # Biologically Plausible Constants
    C: float = 1.0
    gNa: float = 120.0; ENa: float = 50.0
    gK: float = 36.0; EK: float = -77.0
    gL: float = 0.3; EL: float = -54.4
    gA: float = 20.0; EA: float = -80.0
    tauA: float = 20.0
    
    # Synaptic
    Eexc: float = 0.0; Einh: float = -80.0
    tau_syn: float = 5.0 
    tau_in: float = 10.0
    
    # Input Construction
    in_density: float = 0.2
    in_gain: float = 5.0

@dataclass
class TaskConfig:
    """Task-Specific Parameters"""
    poisson_rate_min: float = 10.0
    poisson_rate_max: float = 150.0
    
    # Timing
    dt: float = 0.05
    symbol_ms: float = 20.0 
    
    # Task Specifics
    narma_order: int = 10 
    xor_delay: int = 2
    mc_max_lag: int = 20
    
    # Lyapunov
    lyap_window: Tuple[int, int] = (50, 250)
    lyap_eps: float = 1e-6
    zscore_features: bool = True
    
    # Readout Filter
    tau_trace: float = 20.0

@dataclass
class ESNConfig:
    """Fair ESN Baseline Parameters"""
    N: int = 100
    spectral_radius: float = 0.95
    input_scale: float = 1.0
    density: float = 0.1
    leaking_rate: float = 1.0

@dataclass
class ExperimentConfig:
    """Experiment Execution Control"""
    # Sweep Grids - Coarse
    rho_grid_coarse: List[float] = field(default_factory=lambda: [0.01, 1.5]) # Range forROI
    bias_grid_coarse: List[float] = field(default_factory=lambda: [0.0, 8.0])
    seeds_coarse: int = 5
    seeds_fine: int = 20
    
    # Readout
    cv_folds: int = 5
    cv_gap: int = 10  # window steps
    ridge_alphas: List[float] = field(default_factory=lambda: [1e-6, 1e-4, 1e-2, 1.0, 10.0, 100.0])

    # Ablations
    ablation_mode: str = "none" # 'none', 'no_zscore', 'random_gates'
    
    # Paths
    cache_dir: str = "cache"
    results_dir: str = "results"
    sweep_mode: str = "coarse" # 'coarse', 'fine'

    hh: HHConfig = field(default_factory=HHConfig)
    task: TaskConfig = field(default_factory=TaskConfig)
    esn: ESNConfig = field(default_factory=ESNConfig)

    def get_task_input_id(self) -> str:
        """Determines cache compatibility. capture all input generation and filtering params."""
        id_str = f"{self.task.poisson_rate_min}_{self.task.poisson_rate_max}_"
        id_str += f"{self.task.dt}_{self.task.symbol_ms}_{self.task.zscore_features}_{self.ablation_mode}_"
        id_str += f"{self.task.narma_order}_{self.task.xor_delay}_{self.task.mc_max_lag}_"
        id_str += f"{self.hh.tau_in}_{self.hh.tau_syn}_{self.task.tau_trace}_{self.hh.in_density}_{self.hh.in_gain}"
        return hashlib.sha1(id_str.encode()).hexdigest()


def load_config(path: str) -> ExperimentConfig:
    with open(path, 'r') as f:
        data = yaml.safe_load(f)
    
    hh_data = data.pop('hh', {})
    task_data = data.pop('task', {})
    
    cfg = ExperimentConfig(**data)
    cfg.hh = HHConfig(**hh_data)
    cfg.task = TaskConfig(**task_data)
    return cfg
-e 

========================================
FILE: project_C_poisson/configs/validation_config.yaml
========================================

hh:
  N: 50
  density: 0.2
  conn_type: "dale"
  
task:
  poisson_rate_min: 10.0
  poisson_rate_max: 150.0
  dt: 0.05
  symbol_ms: 20.0
  narma_order: 10 
  xor_delay: 2
  mc_max_lag: 20
  lyap_window: [50, 250]
  lyap_eps: 1.0e-6
  zscore_features: true

esn:
  N: 50

# Validation: Single point from each extreme
rho_grid_coarse: [0.01, 1.5]
bias_grid_coarse: [0.0, 8.0]
seeds_coarse: 2

# Readout Configuration
cv_folds: 2
cv_gap: 5
ridge_alphas: [1.0, 10.0]

# Execution
sweep_mode: "coarse"
cache_dir: "/app/cache"
results_dir: "/app/results"
-e 

========================================
FILE: project_C_poisson/configs/production_config.yaml
========================================

hh:
  N: 100
  density: 0.2
  conn_type: "dale"
  
task:
  poisson_rate_min: 10.0
  poisson_rate_max: 150.0
  dt: 0.05
  symbol_ms: 20.0
  narma_order: 10 
  xor_delay: 2
  mc_max_lag: 20
  lyap_window: [50, 250]
  lyap_eps: 1.0e-6
  zscore_features: true

esn:
  N: 100

# Production Sweep Grid
rho_grid_coarse: [0.01, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5]
bias_grid_coarse: [0.0, 2.0, 4.0, 6.0, 8.0]
seeds_coarse: 20

# Readout Configuration
cv_folds: 5
cv_gap: 10
ridge_alphas: [1.0e-6, 1.0e-4, 1.0e-2, 1.0, 10.0, 100.0]

# Execution
sweep_mode: "coarse"
cache_dir: "/app/cache"
results_dir: "/app/results"
-e 

